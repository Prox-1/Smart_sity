{
  "AGENT_DIRECTORY_NAME": "total_reward_lr01_df099_epd0999_acc_in_rew_30_20_10_0_100eps_7200steps(l_reward_ 1.5 1.2 0.7 g_reward_ 1 1.0 0.5)",
  "ENABLE_ACCIDENTS": true,
  "ACCIDENT_MODE": "obstacle",
  "ACCIDENT_PROB_PER_STEP": 0.01,
  "ACCIDENT_MIN_DURATION": 100,
  "ACCIDENT_MAX_DURATION": 300,
  "ACCIDENT_MAX_CONCURRENT": 20,
  "NUM_EPISODES": 100,
  "MAX_SIMULATION_STEPS": 7200,
  "ACTIONS": [
    30,
    20,
    10,
    0,
    -10,
    -20,
    -30
  ],
  "LEARNING_RATE": 0.1,
  "DISCOUNT_FACTOR": 0.99,
  "EPSILON": 1.0,
  "EPSILON_DECAY": 0.999,
  "MIN_EPSILON": 0.01,
  "USE_ACCIDENT_PENALTY": true,
  "LOCAL_SPEED_WEIGHT": 1.5,
  "LOCAL_WTIME_WEIGHT": 1.2,
  "LOCAL_OCC_WEIGHT": 0.7,
  "GLOBAL_SPEED_WEIGHT": 1.0,
  "GLOBAL_WTIME_WEIGHT": 1.0,
  "GLOBAL_OCC_WEIGHT": 0.5,
  "WEIGHT_LOCAL": 0.5,
  "WEIGHT_GLOBAL": 0.5
}